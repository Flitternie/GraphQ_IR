{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "from importlib import reload\n",
    "\n",
    "random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_program_seq(program):\n",
    "    seq = []\n",
    "    for item in program:\n",
    "        func = item['function']\n",
    "        inputs = item['inputs']\n",
    "        seq.append(func + '(' + '<c>'.join(inputs) + ')')\n",
    "    seq = '<b>'.join(seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 18:30:55.317386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"./bart-base/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bart-base/tokenizer_config.json',\n",
       " './bart-base/special_tokens_map.json',\n",
       " './bart-base/vocab.json',\n",
       " './bart-base/merges.txt',\n",
       " './bart-base/added_tokens.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens([\"<b>\", \"<c>\", \"<E>\",\"</E>\",\"<A>\",\"</A>\",\"<R>\",\"</R>\",\"<V>\",\"</V>\",\"<Q>\",\"</Q>\",\"<C>\",\"</C>\"])\n",
    "# entity, attribute, relation, value, qualifier, concept\n",
    "tokenizer.save_pretrained(\"./bart-base/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bart2query.sparql.sparql_engine import get_sparql_answer\n",
    "from utils.load_kb import DataForSPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading CFQ IR parser\n",
    "from IR_CFQ import sparql_parser\n",
    "sparql_parser = reload(sparql_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = DataForSPARQL(os.path.join(\"./dataset_new/\", 'kb.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open(\"./dataset_full/train.json\"))\n",
    "train_sparql = [item['sparql'] for item in train_data]\n",
    "train_program = [item['program'] for item in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = json.load(open(\"./dataset_full/val.json\"))\n",
    "val_sparql = [item['sparql'] for item in val_data]\n",
    "val_program = [item['program'] for item in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(open(\"./dataset_full/test.json\"))\n",
    "test_sparql = [item['sparql'] for item in test_data]\n",
    "test_program = [item['program'] for item in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data\n",
    "train_data = json.load(open(\"./dataset_new/train.json\"))\n",
    "train_sparql = [item['sparql'] for item in train_data]\n",
    "train_program = [item['program'] for item in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = json.load(open(\"./dataset_new/val.json\"))\n",
    "val_sparql = [item['sparql'] for item in val_data]\n",
    "val_program = [item['program'] for item in val_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(open(\"./dataset_new/test.json\"))\n",
    "test_sparql = [item['sparql'] for item in test_data]\n",
    "test_program = [item['program'] for item in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measuring the average sequence length of sparql and program after being tokenized\n",
    "sparql_total_len = 0\n",
    "program_total_len = 0\n",
    "\n",
    "assert len(train_sparql) == len(train_program)\n",
    "for s, p in zip(train_sparql, train_program):\n",
    "    sparql_total_len += len(tokenizer(s)['input_ids'])\n",
    "    program_total_len += len(tokenizer(get_program_seq(p))['input_ids'])\n",
    "\n",
    "print(\"sparql avg len: %f\\nprogram avg len: %f\" % (sparql_total_len / len(train_sparql), program_total_len / len(train_program)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measuring the average sequence length of ir after being tokenized\n",
    "ir_total_len = 0\n",
    "template_total_len = 0\n",
    "train_template = [i[\"origin\"] for i in train_data]\n",
    "\n",
    "assert len(train_ir) == len(train_template)\n",
    "for ir, template in zip(train_ir, train_template):\n",
    "    ir_total_len += len(tokenizer(ir)['input_ids'])\n",
    "    template_total_len += len(tokenizer(template)['input_ids'])\n",
    "\n",
    "print(\"Template avg len: %f\\nIR avg len: %f\" % (template_total_len / len(train_template), ir_total_len / len(train_ir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(query (whatEntityQuery (entitySet (entitySet (entitySet (entitySet (findAll FindAll())) (filterAttr (filterStr FilterStr( (key (string TOID)) <c> (value (string 4000000074573917)) )))) (filterConcept FilterConcept( (concept (string town)) ))) (entitySet (entitySet (entitySet (findAll FindAll())) (filterAttr (filterStr FilterStr( (key (string OS grid reference)) <c> (value (string SP8778)) )))) (filterConcept FilterConcept( (concept (string town)) ))) (setOP (intersect And()))) (queryName What())) <EOF>)\n"
     ]
    }
   ],
   "source": [
    "import KqaPro_Parser.CallProgramParser\n",
    "reload(KqaPro_Parser.CallProgramParser)\n",
    "from KqaPro_Parser.CallProgramParser import ParsingProgram\n",
    "parser = ParsingProgram()\n",
    "parser.parse(train_program[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(query (whatEntityQuery (entitySet (entitySet (entitySet (entitySet (findAll FindAll())) (filterAttr (filterStr FilterStr( (key (string TOID)) <c> (value (string 4000000074573917)) )))) (filterConcept FilterConcept( (concept (string town)) ))) (entitySet (entitySet (entitySet (findAll FindAll())) (filterAttr (filterStr FilterStr( (key (string OS grid reference)) <c> (value (string SP8778)) )))) (filterConcept FilterConcept( (concept (string town)) ))) (setOP (intersect And()))) (queryName What())) <EOF>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "for i in train_data:\n",
    "    program = get_program_seq(i['program'])\n",
    "    if \"And(\" in program:\n",
    "        target.append([i['sparql'], program, gen_ir(i['program'])])\n",
    "    if len(target) > 10:\n",
    "        break\n",
    "target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import KqaPro_Parser.program_v2.ProgramIRTranslator\n",
    "reload(KqaPro_Parser.program_v2.ProgramIRTranslator)\n",
    "from KqaPro_Parser.program_v2.ProgramIRTranslator import IR_translator\n",
    "translator = IR_translator()\n",
    "\n",
    "def gen_ir(i):\n",
    "    ir = translator.program_to_ir(i)\n",
    "    for token in [\"<E>\",\"</E>\",\"<ES>\",\"</ES>\",\"<A>\",\"</A>\",\"<R>\",\"</R>\",\"<V>\",\"</V>\",\"<Q>\",\"</Q>\",\"<C>\",\"</C>\"]:\n",
    "        ir = ir.replace(\" {}\".format(token), token)\n",
    "        ir = ir.replace(\"{} \".format(token), token)\n",
    "    return ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find(Georgia national football team)<b>QueryAttrQualifier(ranking<c>78<c>review score by)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19399/4193238885.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mir_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19399/930344128.py\u001b[0m in \u001b[0;36mgen_ir\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram_to_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"<E>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"</E>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"<ES>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"</ES>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"<A>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"</A>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"<R>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"</R>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"<V>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"</V>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"<Q>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"</Q>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"<C>\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"</C>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/KqaPro_IR/KqaPro_Parser/program_v2/ProgramIRTranslator.py\u001b[0m in \u001b[0;36mprogram_to_ir\u001b[0;34m(self, program)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetIR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/antlr4/tree/Tree.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, listener, t)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetChildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/antlr4/tree/Tree.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, listener, t)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetChildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/antlr4/tree/Tree.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, listener, t)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetChildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/antlr4/tree/Tree.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(self, listener, t)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/antlr4/tree/Tree.py\u001b[0m in \u001b[0;36mexitRule\u001b[0;34m(self, listener, r)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetRuleContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitEveryRule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/KqaPro_IR/KqaPro_Parser/program_v2/ProgramParser.py\u001b[0m in \u001b[0;36mexitRule\u001b[0;34m(self, listener)\u001b[0m\n\u001b[1;32m   3061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlistener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exitEntity\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3062\u001b[0;31m                 \u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitEntity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/KqaPro_IR/KqaPro_Parser/program_v2/ProgramIREmitter.py\u001b[0m in \u001b[0;36mexitEntity\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexitEntity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mProgramParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEntityContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparentCtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"entity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitEntity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EntitySetAtomContext' object has no attribute 'slots'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19399/4193238885.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_program_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cfq_parser = sparql_parser.KqaParser(train_sparql)\n",
    "ir_list = []\n",
    "for point in train_program[:10]:\n",
    "    try:\n",
    "        ir = gen_ir(point)\n",
    "        ir_list.append(ir)\n",
    "    except Exception:\n",
    "        print(get_program_seq(point))\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is<ES><ES>the<C>town</C><ES><ES>the ones</ES></ES></ES>and<ES>the<C>town</C><ES><ES>the ones</ES></ES></ES></ES>',\n",
       " 'what is the qualifier<Q>review score by</Q>of<E>Georgia national football team</E>whose<A>ranking</A>is<V>78</V>',\n",
       " 'whether<ES>the<C>human</C><E>high school</E></ES><A>name in native language</A>is text<V>Laura Linney</V>',\n",
       " 'which one has the largest<A>elevation above sea level</A>among<ES><E>Baghdad</E>or<ES><E>Jerusalem</E></ES></ES>',\n",
       " 'what is the attribute<A>date of birth</A>of<ES>the<C>human</C><ES><ES>the ones</ES></ES></ES>',\n",
       " 'what is the qualifier<Q>for work</Q>of<ES><ES>the ones <E>Jewish people</E></ES>and<E>John Houseman</E></ES>that<R>nominated for</R>to<E>Academy Award for Best Picture</E>',\n",
       " 'what is the qualifier<Q>point in time</Q>of<ES>the<C>big city</C><ES><ES>the ones</ES></ES></ES>whose<A>population</A>is<V>104072</V>',\n",
       " 'whether<E>Eve Myles</E><A>official website</A>is text<V>http://www.cheechandchong.com</V>',\n",
       " 'what is the relation from<E>alternative rock</E>to<E>Greg Graffin</E>',\n",
       " 'whether<ES>the<C>human</C><ES><ES>the ones</ES></ES></ES><A>name in native language</A>is text<V>Elias Koteas</V>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[]\n",
    "for ir in ir_list:\n",
    "    if \"what is the qualifier\" in ir:\n",
    "        target.append(ir)\n",
    "    if len(target) > 10:\n",
    "        break\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KqaPro_Parser.ir.UnifiedIRLexer import *\n",
    "from KqaPro_Parser.ir.UnifiedIRParser import *\n",
    "\n",
    "from antlr4 import *\n",
    "from antlr4.InputStream import InputStream\n",
    "wrong_list = []\n",
    "for ir in ir_list:\n",
    "    input_stream = InputStream(ir)\n",
    "    lexer = UnifiedIRLexer(input_stream)\n",
    "    token_stream = CommonTokenStream(lexer)\n",
    "    parser = UnifiedIRParser(token_stream)\n",
    "    try:\n",
    "        tree = parser.query()\n",
    "    except:\n",
    "        wrong_list.append(ir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from KqaPro_Parser.program import ProgramIRTranslator\n",
    "translator = ProgramIRTranslator.IR_translator()\n",
    "train_data = json.load(open(\"./dataset_full/train.json\"))\n",
    "for point in train_data:\n",
    "    translator.program_to_ir(point[\"program\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_func = \"Select\"\n",
    "target = []\n",
    "for i in new_train_data:\n",
    "    s = i['rewrite']\n",
    "    p = i['program']\n",
    "    q = i['sparql']\n",
    "    if program_func in get_program_seq(p):\n",
    "        target.append(p)\n",
    "        if len(target) == 20:\n",
    "            break\n",
    "\n",
    "for t in target:\n",
    "    print(get_program_seq(t))\n",
    "    print(program_to_ir(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [line for line in open(\"./exp_results/UIR/val_predict.txt\")]\n",
    "gold = [line for line in open(\"./exp_results/UIR/val_gold.txt\")]\n",
    "wrong = []\n",
    "test_nl = [item[\"rewrite\"] for item in val_data]\n",
    "for nl, g, p in zip(test_nl, gold, pred):\n",
    "    if g != p:\n",
    "        wrong.append([\"nl: \"+nl.strip(), \"gold: \"+g.strip(),\"pred: \"+p.strip()])\n",
    "print(len(wrong))\n",
    "wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "parser = pickle.load(open(\"./exp_files/CFQ_IR/full/parser.pkl\",'rb'))\n",
    "from utils.data import DataLoader, DistributedDataLoader, prepare_dataset\n",
    "train_dataset, train_vocab = prepare_dataset(\"./exp_files/CFQ_IR/full/vocab.json\", \"./exp_files/CFQ_IR/full/train.pt\", training=True, pretrain=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bart2query.program.executor_rule_new import RuleExecutor\n",
    "# from utils.data import load_vocab\n",
    "# vocab = load_vocab(os.path.join(\"./exp_files_new/UIR/full/\", 'vocab.json'))\n",
    "rule_executor = RuleExecutor(os.path.join(\"./dataset_new/\", 'kb.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_executor.key_type[\"publication date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = rule_executor.entities\n",
    "concepts = rule_executor.concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_entity = set()\n",
    "unique_attribute = set()\n",
    "unique_relation = set()\n",
    "# unique_qualifier = set()\n",
    "\n",
    "entity_mapping = dict()\n",
    "entity_attribute_mapping = dict()\n",
    "entity_relation_mapping = dict()\n",
    "\n",
    "for name_id, entity in entities.items():\n",
    "    entity_mapping[name_id] = entity[\"name\"]\n",
    "    unique_entity.add(entity[\"name\"])\n",
    "\n",
    "    entity_attribute_mapping[name_id] = set()\n",
    "    entity_relation_mapping[name_id] = set()\n",
    "\n",
    "    for attribute in entity[\"attributes\"]:\n",
    "        unique_attribute.add(attribute[\"key\"])\n",
    "        entity_attribute_mapping[name_id].add(attribute[\"key\"])    \n",
    "    for relation in entity[\"relations\"]:\n",
    "        unique_relation.add(relation[\"predicate\"])\n",
    "        entity_relation_mapping[name_id].add(relation[\"predicate\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(entity_mapping.keys()))\n",
    "print(len(entity_attribute_mapping.keys()))\n",
    "print(len(unique_entity))\n",
    "print(len(unique_attribute))\n",
    "print(len(unique_relation))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and count repeating entities\n",
    "repeat_entity = dict()\n",
    "for name_id, entity in entity_mapping.items():\n",
    "    if entity in repeat_entity.keys():\n",
    "        repeat_entity[entity][0] += 1\n",
    "        repeat_entity[entity][1].append(name_id)\n",
    "    else:\n",
    "        repeat_entity[entity] = [1, [name_id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_concept = set()\n",
    "concept_mapping = dict()\n",
    "concept_relation_mapping = dict()\n",
    "\n",
    "for name_id, concept in concepts.items():\n",
    "    concept_mapping[name_id] = concept[\"name\"]\n",
    "    unique_concept.add(concept[\"name\"])\n",
    "    \n",
    "    concept_relation_mapping[name_id] = set()\n",
    "    try:\n",
    "        for relation in concept[\"relations\"]:\n",
    "            unique_relation.add(relation[\"predicate\"])\n",
    "            concept_relation_mapping[name_id].add(relation[\"predicate\"])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unique_concept))\n",
    "print(len(unique_relation)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unique_relation:\n",
    "    try:\n",
    "        assert \"{\" not in i and \"}\" not in i\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ir = \"\"\"what is the <Q> for work </Q> of <E> <E> the one that <R> ethnic group </R> backward to <E> Jewish people </E> </E> and <E> John Houseman </E> </E> that <R> nominated for </R> to <E> Academy Award for Best Picture </E>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IR_unified.self_correct import IRCorrector\n",
    "corrector = IRCorrector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = re.findall(r'\\{([^{}]+)\\}', ir.replace(\"<E>\", \"{\").replace(\"</E>\", \"}\"))\n",
    "entities[0].strip() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sparql = [line.strip() for line in open(\"./sparql_results.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "complete_same = 0\n",
    "execute_same = 0\n",
    "wrong = []\n",
    "assert len(pred_sparql) == len(test_sparql)\n",
    "for pred, gold, query, i in tqdm(zip(pred_sparql, test_sparql, range(len(test_data)))):\n",
    "    if pred.strip() == gold.strip():\n",
    "        complete_same += 1\n",
    "        execute_same += 1\n",
    "    elif get_sparql_answer(pred, kb) == get_sparql_answer(gold, kb):\n",
    "        execute_same += 1\n",
    "    else:\n",
    "        wrong.append([query['origin'], pred, gold])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_same, execute_same, len(wrong), len(pred_sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "test_pickle = []\n",
    "for i in range(5):\n",
    "    test_pickle.append(pickle.load(open(\"./exp_files_new/UIR/full/end2end/test.pt\", 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ir = [tokenizer.decode(test_pickle[0][i], skip_special_tokens=True) for i in range(len(test_pickle))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(complete_same/len(pred_sparql), execute_same/len(pred_sparql))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong[:10]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f5681733fccbefcbca5a4e9f72189d3e93347784ed9242ac090fa102fe5e7d6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
